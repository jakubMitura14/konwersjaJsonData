{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import sys\n",
    "import os.path\n",
    "from os import path as pathOs\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import shutil\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "from pathlib import Path\n",
    "import fileinput\n",
    "import re\n",
    "import subprocess\n",
    "from toolz.itertoolz import groupby\n",
    "import seaborn as sns\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import SimpleITK as sitk\n",
    "import mdai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import mdai\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from pydicom.fileset import FileSet\n",
    "from os import path as pathOs\n",
    "from pathlib import Path\n",
    "import toolz\n",
    "from toolz.curried import pipe, map, filter, get\n",
    "from toolz import curry\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "import nnunetv2\n",
    "\n",
    "import elastixRegister as elastixRegister\n",
    "from elastixRegister import reg_a_to_b\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from toolz.itertoolz import groupby\n",
    "from toolz import curry\n",
    "# import multiprocess\n",
    "# p = multiprocess.Pool(os.cpu_count())\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def copy_changing_type(source, dest):\n",
    "    image= sitk.ReadImage(source)\n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in {source}\")\n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    image=sitk.Cast(image, sitk.sitkFloat32)\n",
    "    writer = sitk.ImageFileWriter() \n",
    "    writer.SetFileName(dest)\n",
    "    writer.Execute(image)\n",
    "    return dest\n",
    "\n",
    "#metadata directory\n",
    "resCSVDir='/home/sliceruser/workspaces/konwersjaJsonData/outCsv/resCSV.csv'\n",
    "#directory with inferred prostates\n",
    "dir_inferred_prost='/workspaces/konwersjaJsonData/explore/all_prost_segm_full_files/my_prost_infered'\n",
    "sourceFrame = pd.read_csv(resCSVDir)\n",
    "test_ids = pd.read_csv('/workspaces/konwersjaJsonData/explore/test_ids.csv' )\n",
    "new_col_name= 'inferred_pg'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_id_from_file_name(path_str):\n",
    "    path_str=path_str.replace('.nii.gz','')\n",
    "    path_str=path_str[1:5]\n",
    "    return int(path_str)\n",
    "\n",
    "def add_t2w_to_name(source):\n",
    "    if(source==' '):\n",
    "        return ' '\n",
    "    if('t2w' in source):\n",
    "        return source\n",
    "    new_path= source.replace('.nii.gz','_t2w.nii.gz')\n",
    "    copy_changing_type(source, new_path)\n",
    "    return new_path\n",
    "\n",
    "def add_inferred_full_prost_to_dataframe(dir_inferred_prost, df,new_col_name):\n",
    "    \"\"\" \n",
    "    we have some inferred anatomical segmentations done by previous \n",
    "    models now we want to take the folder with \n",
    "    \"\"\"\n",
    "    list_files= os.listdir(dir_inferred_prost)\n",
    "    list_files= list(filter(lambda el : el[0]=='9' ,list_files ))\n",
    "    list_ids= list(map(get_id_from_file_name,list_files))\n",
    "    list_files= list(map( lambda el: f\"{dir_inferred_prost}/{el}\" ,list_files))\n",
    "    file_and_id= dict(list(zip(list_ids,list_files)))\n",
    "    new_col_dat= list(map( lambda el: file_and_id.get(el,' ') ,df['masterolds'].to_numpy() ))\n",
    "    #changing path name to mark it is t2w related\n",
    "    new_col_dat= list(map(add_t2w_to_name,new_col_dat))\n",
    "\n",
    "    df[new_col_name]=new_col_dat\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols=sourceFrame.columns\n",
    "noSegCols=list(filter(lambda el: '_noSeg' in el , cols))+['series_MRI_path']\n",
    "lesion_cols=list(filter(lambda el: 'lesion' in el , noSegCols))\n",
    "\n",
    "sourceFrame=add_inferred_full_prost_to_dataframe(dir_inferred_prost, sourceFrame,new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def groupByMaster(rowws):\n",
    "    grouped_by_master= groupby(lambda row : row[1]['masterolds'],rowws)\n",
    "    # grouped_by_master=[(key,list(group)) for key, group in grouped_by_master]\n",
    "    return dict(grouped_by_master).items()\n",
    "\n",
    "\n",
    "\n",
    "def get_bool_arr_from_path(pathh):\n",
    "    \"\"\"\n",
    "    given path reads it and return associated array\n",
    "    then it casts it to boolean data type\n",
    "    \"\"\"\n",
    "    imageA=sitk.ReadImage(pathh)\n",
    "    return sitk.GetArrayFromImage(imageA).astype(bool)\n",
    "\n",
    "\n",
    "def getPathsFromRow(row,list_columns):\n",
    "    \"\"\"\n",
    "    extracting all paths of intrest from row\n",
    "    \"\"\"\n",
    "    res=  map( lambda colName : (colName,row[1][colName] ),list_columns )\n",
    "    return res\n",
    "\n",
    "def getListModality(modalityName,pathhs,non_mri_inputs):\n",
    "    \"\"\"\n",
    "    getting paths related to single modality and extracting main MRI image\n",
    "    non_mri_inputs - some inputs that are designed to be put into input channels \n",
    "    \"\"\"\n",
    "    if(modalityName not in non_mri_inputs):\n",
    "        # we are intrested only in paths that has the prostate segmentation\n",
    "        pathhs=list(map(lambda el: el[1],pathhs))\n",
    "        # pathhs= list(filter(lambda el :\"pg_t2w.nii.gz\" not in el , pathhs))\n",
    "        mod_paths = list(filter(lambda pathh :modalityName in  pathh,pathhs))\n",
    "        mri = list(filter(lambda el: '.mha' in el ,mod_paths))\n",
    "        if(len(mri)==0):\n",
    "            return ' ',[]\n",
    "        mri=mri[0]   \n",
    "        mod_paths= list(filter(lambda pathh: '.mha' not in pathh , mod_paths))\n",
    "        return (modalityName,(mri,np.unique(mod_paths).tolist()))\n",
    "    \n",
    "    elif(modalityName in non_mri_inputs):\n",
    "        # colNames=list(map(lambda el: el[0],pathhs))\n",
    "        pathhss= list(filter(lambda el :modalityName in el[0] , pathhs))   \n",
    "        if(len(pathhss)==0):\n",
    "            return ' ',[]        \n",
    "        res= (modalityName, (modalityName,np.unique(pathhss[0][1]).tolist())  )\n",
    "        return res\n",
    "\n",
    "\n",
    "def myFlatten(liist):\n",
    "    return  itertools.chain(*liist)\n",
    "\n",
    "def map_modalities(pathhs,modalities,non_mri_inputs):\n",
    "    all_modalities=modalities+non_mri_inputs\n",
    "    res= toolz.pipe(all_modalities\n",
    "                ,map(partial(getListModality,pathhs=pathhs,non_mri_inputs=non_mri_inputs))\n",
    "                ,list\n",
    "            )\n",
    "    # print(f\"gggg {res}\")\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def iterGroupModalities(groupTuple,modalities_of_intrest,label_cols,non_mri_inputs ):\n",
    "    \"\"\"\n",
    "    grouping the paths into dictionary relative to modalities they represent and lesions on thise \n",
    "    modalities\n",
    "    \"\"\"\n",
    "    masterOlds, listRows= groupTuple\n",
    "    pathhs=toolz.pipe(listRows\n",
    "                ,map(partial(getPathsFromRow,list_columns=np.unique(label_cols+['series_MRI_path']+non_mri_inputs)))\n",
    "                ,myFlatten\n",
    "                # ,filter(lambda el : len(el)>2)\n",
    "                ,list\n",
    "                ,partial(map_modalities,modalities=modalities_of_intrest,non_mri_inputs=non_mri_inputs)\n",
    "                ,dict\n",
    "                )   \n",
    "    return (masterOlds,pathhs)\n",
    "\n",
    "\n",
    "\n",
    "def get_bool_or(pathA,pathB):\n",
    "    if(isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathA),get_bool_arr_from_path(pathB))\n",
    "    elif(isinstance(pathA, str) and not isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathA),pathB)\n",
    "    elif(not isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathB),pathA)\n",
    "    else:\n",
    "        return np.logical_or(pathB,pathA)\n",
    "\n",
    "def get_bool_and(pathA,pathB):\n",
    "    if(isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathA),get_bool_arr_from_path(pathB))\n",
    "    elif(isinstance(pathA, str) and not isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathA),pathB)\n",
    "    elif(not isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathB),pathA)\n",
    "    else:\n",
    "        return np.logical_and(pathB,pathA)\n",
    "\n",
    "\n",
    "def get_4_id(masterolds):\n",
    "    \"\"\"\n",
    "    take master id and changes it into string that starts with 0s and have always length 4\n",
    "    \"\"\"\n",
    "    masteroldsStand=str(masterolds)\n",
    "    if(len(masteroldsStand)==1):\n",
    "        return f\"000{masteroldsStand}\"\n",
    "    elif(len(masteroldsStand)==2):\n",
    "        return f\"00{masteroldsStand}\"\n",
    "    elif(len(masteroldsStand)==3):\n",
    "        return f\"0{masteroldsStand}\"\n",
    "    return masteroldsStand\n",
    "\n",
    "def save_from_arr(zeroArray,image3D,newPathLab):\n",
    "    \"\"\"\n",
    "    given array saves it to file into defined path using simpleitk\n",
    "    \"\"\"\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    image = sitk.GetImageFromArray(zeroArray.astype(float).astype(np.uint8))  \n",
    "    nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    if(nan_count>0):\n",
    "        raise ValueError(f\"!!! nan in image would be saved as {newPathLab}\")\n",
    "\n",
    "    image.SetSpacing(image3D.GetSpacing())\n",
    "    image.SetOrigin(image3D.GetOrigin())\n",
    "    image.SetDirection(image3D.GetDirection())   \n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    writer.SetFileName(newPathLab)\n",
    "    writer.Execute(image)\n",
    "\n",
    "def copy_changing_type(source, dest):\n",
    "    image= sitk.ReadImage(source)\n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in {source}\")\n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    image=sitk.Cast(image, sitk.sitkFloat32)\n",
    "    writer = sitk.ImageFileWriter() \n",
    "    writer.SetFileName(dest)\n",
    "    writer.Execute(image)\n",
    "    return dest\n",
    "\n",
    "# mod=\"adc\"\n",
    "def get_key_by_value(mod,channel_names):\n",
    "    return list(channel_names.keys())[list(channel_names.values()).index(mod)]\n",
    "\n",
    "def prepare_out_paths(group,modalities_of_intrest,labelsTrFolder,imagesTrFolder,non_mri_inputs,channel_names ):\n",
    "    #preparing names\n",
    "    for_id=get_4_id(group[0])\n",
    "    label_new_path= join(labelsTrFolder,f\"9{for_id}00.nii.gz\" )\n",
    "    # prostate_path=join(imagesTrFolder,f\"9{for_id}00_000{3}.nii.gz\" )\n",
    "    out_pathsDict= list(map( lambda mod:(mod,join(imagesTrFolder,f\"9{for_id}00_000{get_key_by_value(mod,channel_names)}.nii.gz\" )) ,np.unique(modalities_of_intrest+non_mri_inputs) ))\n",
    "    out_pathsDict=dict(out_pathsDict)\n",
    "    return label_new_path,out_pathsDict\n",
    "\n",
    "# with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "# #with mp.Pool(processes = 1) as pool:\n",
    "#     @curry  \n",
    "#     def pmap(fun,iterable):\n",
    "#         return pool.map(fun,iterable)\n",
    "    \n",
    "def reg_a_to_b_by_metadata_single_c(fixed_image_path,moving_image_path,interpolator):\n",
    "    # print(f\"fixed_image_path {fixed_image_path} moving_image_path {moving_image_path}\")\n",
    "    # moving_image_path=moving_image_path[0]\n",
    "    fixed_image=sitk.ReadImage(fixed_image_path)\n",
    "    moving_image=sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # fixed_image=sitk.Cast(fixed_image, sitk.sitkUInt8)\n",
    "    # moving_image=sitk.Cast(moving_image, sitk.sitkInt)\n",
    "    \n",
    "    arr=sitk.GetArrayFromImage(moving_image)\n",
    "    resampled=sitk.Resample(moving_image, fixed_image, sitk.Transform(3, sitk.sitkIdentity), interpolator, 0)\n",
    "    return sitk.GetArrayFromImage(resampled)\n",
    "    \n",
    "def reg_a_to_b_by_metadata_single_b(fixed_image_path,moving_image_path,out_folder, interpolator=sitk.sitkNearestNeighbor):\n",
    "    if(len(moving_image_path)<4):\n",
    "        moving_image_path=moving_image_path[0]\n",
    "    fixed_image=sitk.ReadImage(fixed_image_path)\n",
    "    moving_image=sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # fixed_image=sitk.Cast(fixed_image, sitk.sitkUInt8)\n",
    "    # moving_image=sitk.Cast(moving_image, sitk.sitkInt)\n",
    "    \n",
    "    arr=sitk.GetArrayFromImage(moving_image)\n",
    "    resampled=sitk.Resample(moving_image, fixed_image, sitk.Transform(3, sitk.sitkIdentity), interpolator, 0)\n",
    "    \n",
    "    # print(f\" prim sum {np.sum(sitk.GetArrayFromImage(sitk.ReadImage(moving_image_path)).flatten())} \\n suuum {np.sum(sitk.GetArrayFromImage(resampled).flatten())} \")\n",
    "  \n",
    "    writer = sitk.ImageFileWriter()\n",
    "    new_path= join(out_folder,moving_image_path.split('/')[-1])\n",
    "    writer.SetFileName(new_path)\n",
    "    writer.Execute(resampled)\n",
    "\n",
    "    return new_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_crop(image,min_z,min_y,min_x,max_z,max_x,max_y):\n",
    "    size=[int(max_y-min_y)-1,int(max_x-min_x)-1,int(max_z-min_z)-1]\n",
    "    beg=[int(min_y),int(min_x),int(min_z)]\n",
    "    # size=[int(max_x-min_x)-1,int(max_y-min_y)-1,int(max_z-min_z)-1]\n",
    "    # beg=[int(min_x), int(min_y),int(min_z)]\n",
    "    extract = sitk.ExtractImageFilter()\n",
    "    extract.SetSize(size)\n",
    "    extract.SetIndex(beg)\n",
    "    extracted_image = extract.Execute(image)\n",
    "    return extracted_image\n",
    "\n",
    "\n",
    "\n",
    "def get_from_arr(zeroArray,image3D):\n",
    "    \"\"\"\n",
    "    given array saves it to file into defined path using simpleitk\n",
    "    \"\"\"\n",
    "    image = sitk.GetImageFromArray(zeroArray.astype(float).astype(np.uint8))  \n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in image would be saved as {newPathLab}\")\n",
    "\n",
    "    image.SetSpacing(image3D.GetSpacing())\n",
    "    image.SetOrigin(image3D.GetOrigin())\n",
    "    image.SetDirection(image3D.GetDirection())   \n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    return image\n",
    "\n",
    "def visualize_range(group,main_modality,modalities_of_intrest,non_mri_inputs,out_folder):\n",
    "\n",
    "    modalit_path_add= list(map( lambda el:(group[1][el]) ,non_mri_inputs))\n",
    "    # print(f\"ggg group[1] {group[1]}\")\n",
    "    # print(f\"modalit_path_add[0][1] {modalit_path_add[0][1]}\")\n",
    "    if(modalit_path_add[0][1][0]==' '):\n",
    "        print(f\"no prostate! {group[0]}\")\n",
    "        return group[0]\n",
    "\n",
    "    modalities_of_intrest_without_main= ['hbv']\n",
    "    # modalities_of_intrest_without_main=non_mri_inputs+modalities_of_intrest_without_main\n",
    "\n",
    "    sources_dict=group[1]\n",
    "    sources_dict[non_mri_inputs[0]]=(modalit_path_add[0][1][0],)\n",
    "\n",
    "\n",
    "    registered_modalities_arrs= list(map(lambda mod: reg_a_to_b_by_metadata_single_c(sources_dict[main_modality][0],sources_dict[mod][0], sitk.sitkBSpline)                                    \n",
    "                                                      ,modalities_of_intrest_without_main ))\n",
    "    registered_prostate= list(map(lambda mod: reg_a_to_b_by_metadata_single_c(sources_dict[main_modality][0],sources_dict[mod][0], sitk.sitkNearestNeighbor)                                    \n",
    "                                                      ,non_mri_inputs ))\n",
    "\n",
    "    adc_arr=sitk.GetArrayFromImage(sitk.ReadImage(group[1][main_modality][0]))\n",
    "    prostate_arr= registered_prostate[0]\n",
    "    hbv_arr= registered_modalities_arrs[0]\n",
    "\n",
    "    ########### manage labels\n",
    "\n",
    "    labels_hbv=group[1]['hbv'][1]\n",
    "    labels_adc=group[1][main_modality][1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    labels_hbv_arrs=list(map(lambda pathh_moving: reg_a_to_b_by_metadata_single_b(sources_dict[main_modality][0],pathh_moving,out_folder,sitk.sitkNearestNeighbor)                                    \n",
    "                                                      ,labels_hbv ))\n",
    "\n",
    "    labels= labels_adc+labels_hbv\n",
    "    labRes= np.zeros_like(adc_arr)\n",
    "    if(len(labels)>0):\n",
    "\n",
    "        print(f\"labels {labels}\")\n",
    "        label_names=list(map(lambda pathh:  \n",
    "                            list(filter( lambda el_out:'/' not in el_out ,\n",
    "                                list(filter(lambda el: 'lesion' in el  ,pathh.split('_')))))[0]\n",
    "                            \n",
    "                            ,labels ))\n",
    "\n",
    "        label_names= list(filter( lambda el: '/' not in el ,label_names))\n",
    "        # we want to get sum of all labels of the same name - so lesion 1 sum lesion 2 sum ...\n",
    "        # then we encode it in separate file \n",
    "        zipped_names= list(zip(label_names,labels))\n",
    "\n",
    "        grouped_by_lesion_num = dict(groupby(lambda tupl :tupl[0],zipped_names)).items()\n",
    "        grouped_by_lesion_num= list(map(lambda grouped :  (grouped[0],list(map(lambda el: el[1],grouped[1])) ) , grouped_by_lesion_num  ))\n",
    "        print(f\"\\n grouped_by_lesion_num {grouped_by_lesion_num} \\n\")\n",
    "        grouped_by_lesion_num_arrs= list(map(lambda grouped :  np.array(functools.reduce(get_bool_and, grouped[1])),grouped_by_lesion_num  ))\n",
    "        grouped_by_lesion_num_arrs= np.stack(grouped_by_lesion_num_arrs,axis=0).astype(int)\n",
    "        reduced_common= np.sum(grouped_by_lesion_num_arrs,axis=0)\n",
    "\n",
    "        reduced_sum = np.array(functools.reduce(get_bool_or, labels)).astype(bool)\n",
    "        reduced_sum= ndimage.binary_dilation(reduced_sum,iterations=3)\n",
    "\n",
    "\n",
    "        print(f\"reduced_sum {np.sum(reduced_sum.flatten())}  reduced_common {np.sum(reduced_common.flatten())}\")\n",
    "        labRes=reduced_sum.astype(int)\n",
    "        labRes=labRes+(reduced_common.astype(int))\n",
    "    # label_names=list(map(lambda pathh:  \n",
    "    #                      list(filter( lambda el_out:'/' not in el_out ,\n",
    "    #                         list(filter(lambda el: 'lesion' in el  ,pathh.split('_')))))[0]\n",
    "                         \n",
    "    #                      ,labels ))\n",
    "    # label_names= list(filter( lambda el: '/' not in el ,label_names))\n",
    "    # # we want to get sum of all labels of the same name - so lesion 1 sum lesion 2 sum ...\n",
    "    # # then we encode it in separate file \n",
    "    # zipped_names= list(zip(label_names,labels))\n",
    "\n",
    "    # grouped_by_lesion_num = dict(groupby(lambda tupl :tupl[0],zipped_names)).items()\n",
    "    # grouped_by_lesion_num= list(map(lambda grouped :  (grouped[0],list(map(lambda el: el[1],grouped[1])) ) , grouped_by_lesion_num  ))\n",
    "    # print(f\"\\n grouped_by_lesion_num {grouped_by_lesion_num} \\n\")\n",
    "    # grouped_by_lesion_num_arrs= list(map(lambda grouped :  (grouped[0],np.array(functools.reduce(get_bool_or, grouped[1]))),grouped_by_lesion_num  ))\n",
    "    # label_names_uniq=list(map(lambda el: el[0] ,grouped_by_lesion_num))\n",
    "    # label_nums= list(map(lambda name: \"\".join(list(filter(lambda el:el.isdigit(),name)))  ,label_names_uniq))\n",
    "\n",
    "\n",
    "    # grouped_by_lesion_num_arrs= list(map(lambda arr ,ndimage.binary_dilation(arr,iterations=1),grouped_by_lesion_num_arrs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    prostate_arr_indicies= np.argwhere(prostate_arr)\n",
    "\n",
    "\n",
    "\n",
    "    add_padd_z=50\n",
    "    add_padd_x=14\n",
    "    add_padd_y=14\n",
    "\n",
    "    max_z= np.max(prostate_arr_indicies[:,0])+add_padd_z\n",
    "    min_z= np.min(prostate_arr_indicies[:,0])-add_padd_z\n",
    "    # min_z=0\n",
    "    # max_z=adc_arr.shape[0]\n",
    "    max_x= np.max(prostate_arr_indicies[:,1])+add_padd_x\n",
    "    min_x= np.min(prostate_arr_indicies[:,1])-add_padd_x\n",
    "\n",
    "    max_y= np.max(prostate_arr_indicies[:,2])+add_padd_y\n",
    "    min_y= np.min(prostate_arr_indicies[:,2])-add_padd_y\n",
    "    \n",
    "    min_z=max(min_z,0)\n",
    "    min_y=max(min_y,0)\n",
    "    min_x=max(min_x,0)\n",
    "\n",
    "    max_z=min(max_z,prostate_arr.shape[0]-1)\n",
    "    max_x=min(max_x,prostate_arr.shape[1]-1)\n",
    "    max_y=min(max_y,prostate_arr.shape[2]-1)\n",
    "\n",
    "\n",
    "    print(f\"max_z {max_z} min_z {min_z} max_x {max_x} min_x {min_x} max_y {max_y} min_y {min_y}\")\n",
    "\n",
    "    adc_image = sitk.ReadImage(group[1][main_modality][0])\n",
    "    hbv_image = get_from_arr(hbv_arr,adc_image)\n",
    "    label_image = get_from_arr(labRes,adc_image)\n",
    "\n",
    "\n",
    "    adc_image=my_crop(adc_image,min_z,min_y,min_x,max_z,max_x,max_y)\n",
    "    hbv_image=my_crop(hbv_image,min_z,min_y,min_x,max_z,max_x,max_y)\n",
    "    label_image=my_crop(label_image,min_z,min_y,min_x,max_z,max_x,max_y)\n",
    "\n",
    "    adc_arr=sitk.GetArrayFromImage(adc_image)\n",
    "    hbv_arr=sitk.GetArrayFromImage(hbv_image)\n",
    "    labRes=sitk.GetArrayFromImage(label_image)\n",
    "\n",
    "\n",
    "    # min_x=0\n",
    "    # max_x=adc_arr.shape[1]\n",
    "\n",
    "    # min_y=0\n",
    "    # max_y=adc_arr.shape[2]\n",
    "\n",
    "    # adc_arr=adc_arr[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "    # hbv_arr=hbv_arr[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "    # prostate_arr=prostate_arr[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "    # labRes=labRes[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "\n",
    "    big_prost_z=einops.reduce(labRes,'z x y-> z','sum')\n",
    "    slice=np.argmax(big_prost_z)\n",
    "\n",
    "    big_prost_x=einops.reduce(prostate_arr,'z x y-> x','sum')\n",
    "    on_x=np.argmax(big_prost_z)\n",
    "\n",
    "    \n",
    "    prost= prostate_arr[slice,:,:]\n",
    "    image_to_disp_big= adc_arr[0,:,:]\n",
    "    image_to_disp_on_x= adc_arr[-1,:,:]\n",
    "    # mean= np.mean(image_to_disp_big.flatten())\n",
    "    # std= np.std(image_to_disp_big.flatten())\n",
    "    # print(f\"stddd {std}\")\n",
    "    # # image_to_disp_big= np.clip(image_to_disp_big,mean+1000, mean-1000)\n",
    "    # image_to_disp_big= np.clip(image_to_disp_big,-10000.0, 100000.0)\n",
    "\n",
    "    # with_boundaries=mark_boundaries(image_to_disp_big, prost.astype(int) )\n",
    "    # with_boundaries=mark_boundaries(image_to_disp_big, prost.astype(int) )\n",
    "    fig, axs = plt.subplots(ncols=3)\n",
    "\n",
    "    # sns.heatmap(image_to_disp_big,cmap=\"Greys\" ,ax=axs[0])\n",
    "    # sns.heatmap(image_to_disp_on_x,cmap=\"Greys\" ,ax=axs[1])\n",
    "    # plt.imshow(with_boundaries)\n",
    "    sns.heatmap(adc_arr[slice,:,:],cmap=\"Greys\" ,ax=axs[0] )\n",
    "    sns.heatmap(hbv_arr[slice,:,:],cmap=\"Greys\" ,ax=axs[1] )\n",
    "    sns.heatmap(labRes[slice,:,:],cmap=\"Greys\" ,ax=axs[2] )\n",
    "    plt.show()\n",
    "\n",
    "    # registered_modalities= list(map(lambda mod: reg_a_to_b(join(temp_dir,mod),group[0],group[1][main_modality][0],group[1][mod][0],group[1][mod][1],reg_prop\n",
    "    #                                                             ,elacticPath,transformix_path,mod)\n",
    "                        # ,modalities_of_intrest_without_main   ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_ids = pd.read_csv('/workspaces/konwersjaJsonData/explore/test_ids.csv' ).to_numpy().flatten()\n",
    "\n",
    "test_ids= list(map(lambda el: str(el).strip(),test_ids ))\n",
    "filter_ids=lambda row: str(row[1]['masterolds']).strip() not in test_ids\n",
    "modalities_of_intrest=['t2w','adc','hbv']\n",
    "cols=sourceFrame.columns\n",
    "noSegCols=list(filter(lambda el: '_noSeg' in el , cols))+['series_MRI_path']\n",
    "lesion_cols=list(filter(lambda el: 'lesion' in el , noSegCols))\n",
    "main_modality = 'adc'\n",
    "non_mri_inputs=[new_col_name]\n",
    "out_folder='/workspaces/konwersjaJsonData/explore/temp'\n",
    "# with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "# with mp.Pool(processes = 1) as pool:\n",
    "#     @curry  \n",
    "#     def pmap(fun,iterable):\n",
    "#         return pool.map(fun,iterable)\n",
    "\n",
    "ids=toolz.pipe(sourceFrame.iterrows()\n",
    "                                ,filter(lambda row: row[1]['series_desc'] in modalities_of_intrest)\n",
    "                                ,filter(filter_ids) # filter out all of the test cases\n",
    "                                ,groupByMaster\n",
    "                                ,map(partial(iterGroupModalities,modalities_of_intrest=modalities_of_intrest,label_cols=lesion_cols,non_mri_inputs=non_mri_inputs))\n",
    "                                ,filter(lambda group: ' ' not in group[1].keys() )\n",
    "                                ,list\n",
    "                                ,map(partial(visualize_range,main_modality=main_modality,modalities_of_intrest=modalities_of_intrest,non_mri_inputs=non_mri_inputs,out_folder=out_folder))                            \n",
    "                                ,list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=sourceFrame['masterolds'].to_numpy()\n",
    "99461 in aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(filter(lambda idd: str(idd) in list(map(str,test_ids)), ids))\n",
    "list(filter(lambda idd: int(idd) in list(map(int,test_ids)) , ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/MIC-DKFZ/nnUNet.git\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
