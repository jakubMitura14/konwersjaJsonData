{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import sys\n",
    "import os.path\n",
    "from os import path as pathOs\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import shutil\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "from pathlib import Path\n",
    "import fileinput\n",
    "import re\n",
    "import subprocess\n",
    "from toolz.itertoolz import groupby\n",
    "import seaborn as sns\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import SimpleITK as sitk\n",
    "import mdai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import mdai\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from pydicom.fileset import FileSet\n",
    "from os import path as pathOs\n",
    "from pathlib import Path\n",
    "import toolz\n",
    "from toolz.curried import pipe, map, filter, get\n",
    "from toolz import curry\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "import nnunetv2\n",
    "\n",
    "import elastixRegister as elastixRegister\n",
    "from elastixRegister import reg_a_to_b\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from toolz.itertoolz import groupby\n",
    "from toolz import curry\n",
    "# import multiprocess\n",
    "# p = multiprocess.Pool(os.cpu_count())\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def copy_changing_type(source, dest):\n",
    "    image= sitk.ReadImage(source)\n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in {source}\")\n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    image=sitk.Cast(image, sitk.sitkFloat32)\n",
    "    writer = sitk.ImageFileWriter() \n",
    "    writer.SetFileName(dest)\n",
    "    writer.Execute(image)\n",
    "    return dest\n",
    "\n",
    "#metadata directory\n",
    "resCSVDir='/home/sliceruser/workspaces/konwersjaJsonData/outCsv/resCSV.csv'\n",
    "#directory with inferred prostates\n",
    "dir_inferred_prost='/workspaces/konwersjaJsonData/explore/all_prost_segm_full_files/my_prost_infered'\n",
    "sourceFrame = pd.read_csv(resCSVDir)\n",
    "test_ids = pd.read_csv('/workspaces/konwersjaJsonData/explore/test_ids.csv' )\n",
    "new_col_name= 'inferred_pg'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_id_from_file_name(path_str):\n",
    "    path_str=path_str.replace('.nii.gz','')\n",
    "    path_str=path_str[1:5]\n",
    "    return int(path_str)\n",
    "\n",
    "def add_t2w_to_name(source):\n",
    "    if(source==' '):\n",
    "        return ' '\n",
    "    if('t2w' in source):\n",
    "        return source\n",
    "    new_path= source.replace('.nii.gz','_t2w.nii.gz')\n",
    "    copy_changing_type(source, new_path)\n",
    "    return new_path\n",
    "\n",
    "def add_inferred_full_prost_to_dataframe(dir_inferred_prost, df,new_col_name):\n",
    "    \"\"\" \n",
    "    we have some inferred anatomical segmentations done by previous \n",
    "    models now we want to take the folder with \n",
    "    \"\"\"\n",
    "    list_files= os.listdir(dir_inferred_prost)\n",
    "    list_files= list(filter(lambda el : el[0]=='9' ,list_files ))\n",
    "    list_ids= list(map(get_id_from_file_name,list_files))\n",
    "    list_files= list(map( lambda el: f\"{dir_inferred_prost}/{el}\" ,list_files))\n",
    "    file_and_id= dict(list(zip(list_ids,list_files)))\n",
    "    new_col_dat= list(map( lambda el: file_and_id.get(el,' ') ,df['masterolds'].to_numpy() ))\n",
    "    #changing path name to mark it is t2w related\n",
    "    new_col_dat= list(map(add_t2w_to_name,new_col_dat))\n",
    "\n",
    "    df[new_col_name]=new_col_dat\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols=sourceFrame.columns\n",
    "noSegCols=list(filter(lambda el: '_noSeg' in el , cols))+['series_MRI_path']\n",
    "lesion_cols=list(filter(lambda el: 'lesion' in el , noSegCols))\n",
    "\n",
    "sourceFrame=add_inferred_full_prost_to_dataframe(dir_inferred_prost, sourceFrame,new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True],\n",
       "        [ True, False,  True],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "main_shape=(1,5,5,5,1)\n",
    "input = torch.ones((main_shape))\n",
    "target = torch.ones((main_shape))\n",
    "\n",
    "target[0,2,2,2,0]=2.0\n",
    "\n",
    "# weight = torch.ones((main_shape))\n",
    "# # weight[0,2,2,2,0]=0.0\n",
    "\n",
    "# torch.nn.functional.binary_cross_entropy(input, target, weight=weight)\n",
    "target = torch.ones((3,3))\n",
    "target[1,1]=0.4\n",
    "\n",
    "# a=(target==2)\n",
    "# b=(target==1)\n",
    "\n",
    "# a | b\n",
    "\n",
    "target.round().bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def groupByMaster(rowws):\n",
    "    grouped_by_master= groupby(lambda row : row[1]['masterolds'],rowws)\n",
    "    # grouped_by_master=[(key,list(group)) for key, group in grouped_by_master]\n",
    "    return dict(grouped_by_master).items()\n",
    "\n",
    "\n",
    "\n",
    "def get_bool_arr_from_path(pathh):\n",
    "    \"\"\"\n",
    "    given path reads it and return associated array\n",
    "    then it casts it to boolean data type\n",
    "    \"\"\"\n",
    "    imageA=sitk.ReadImage(pathh)\n",
    "    return sitk.GetArrayFromImage(imageA).astype(bool)\n",
    "\n",
    "\n",
    "def getPathsFromRow(row,list_columns):\n",
    "    \"\"\"\n",
    "    extracting all paths of intrest from row\n",
    "    \"\"\"\n",
    "    res=  map( lambda colName : (colName,row[1][colName] ),list_columns )\n",
    "    return res\n",
    "\n",
    "def getListModality(modalityName,pathhs,non_mri_inputs):\n",
    "    \"\"\"\n",
    "    getting paths related to single modality and extracting main MRI image\n",
    "    non_mri_inputs - some inputs that are designed to be put into input channels \n",
    "    \"\"\"\n",
    "    if(modalityName not in non_mri_inputs):\n",
    "        # we are intrested only in paths that has the prostate segmentation\n",
    "        pathhs=list(map(lambda el: el[1],pathhs))\n",
    "        # pathhs= list(filter(lambda el :\"pg_t2w.nii.gz\" not in el , pathhs))\n",
    "        mod_paths = list(filter(lambda pathh :modalityName in  pathh,pathhs))\n",
    "        mri = list(filter(lambda el: '.mha' in el ,mod_paths))\n",
    "        if(len(mri)==0):\n",
    "            return ' ',[]\n",
    "        mri=mri[0]   \n",
    "        mod_paths= list(filter(lambda pathh: '.mha' not in pathh , mod_paths))\n",
    "        return (modalityName,(mri,np.unique(mod_paths).tolist()))\n",
    "    \n",
    "    elif(modalityName in non_mri_inputs):\n",
    "        # colNames=list(map(lambda el: el[0],pathhs))\n",
    "        pathhss= list(filter(lambda el :modalityName in el[0] , pathhs))   \n",
    "        if(len(pathhss)==0):\n",
    "            return ' ',[]        \n",
    "        res= (modalityName, (modalityName,np.unique(pathhss[0][1]).tolist())  )\n",
    "        return res\n",
    "\n",
    "\n",
    "def myFlatten(liist):\n",
    "    return  itertools.chain(*liist)\n",
    "\n",
    "def map_modalities(pathhs,modalities,non_mri_inputs):\n",
    "    all_modalities=modalities+non_mri_inputs\n",
    "    res= toolz.pipe(all_modalities\n",
    "                ,map(partial(getListModality,pathhs=pathhs,non_mri_inputs=non_mri_inputs))\n",
    "                ,list\n",
    "            )\n",
    "    # print(f\"gggg {res}\")\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def iterGroupModalities(groupTuple,modalities_of_intrest,label_cols,non_mri_inputs ):\n",
    "    \"\"\"\n",
    "    grouping the paths into dictionary relative to modalities they represent and lesions on thise \n",
    "    modalities\n",
    "    \"\"\"\n",
    "    masterOlds, listRows= groupTuple\n",
    "    pathhs=toolz.pipe(listRows\n",
    "                ,map(partial(getPathsFromRow,list_columns=np.unique(label_cols+['series_MRI_path']+non_mri_inputs)))\n",
    "                ,myFlatten\n",
    "                # ,filter(lambda el : len(el)>2)\n",
    "                ,list\n",
    "                ,partial(map_modalities,modalities=modalities_of_intrest,non_mri_inputs=non_mri_inputs)\n",
    "                ,dict\n",
    "                )   \n",
    "    return (masterOlds,pathhs)\n",
    "\n",
    "\n",
    "\n",
    "def get_bool_or(pathA,pathB):\n",
    "    if(isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathA),get_bool_arr_from_path(pathB))\n",
    "    elif(isinstance(pathA, str) and not isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathA),pathB)\n",
    "    elif(not isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathB),pathA)\n",
    "    else:\n",
    "        return np.logical_or(pathB,pathA)\n",
    "\n",
    "def get_bool_and(pathA,pathB):\n",
    "    if(isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathA),get_bool_arr_from_path(pathB))\n",
    "    elif(isinstance(pathA, str) and not isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathA),pathB)\n",
    "    elif(not isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathB),pathA)\n",
    "    else:\n",
    "        return np.logical_or(pathB,pathA)\n",
    "\n",
    "\n",
    "def get_4_id(masterolds):\n",
    "    \"\"\"\n",
    "    take master id and changes it into string that starts with 0s and have always length 4\n",
    "    \"\"\"\n",
    "    masteroldsStand=str(masterolds)\n",
    "    if(len(masteroldsStand)==1):\n",
    "        return f\"000{masteroldsStand}\"\n",
    "    elif(len(masteroldsStand)==2):\n",
    "        return f\"00{masteroldsStand}\"\n",
    "    elif(len(masteroldsStand)==3):\n",
    "        return f\"0{masteroldsStand}\"\n",
    "    return masteroldsStand\n",
    "\n",
    "def save_from_arr(zeroArray,image3D,newPathLab):\n",
    "    \"\"\"\n",
    "    given array saves it to file into defined path using simpleitk\n",
    "    \"\"\"\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    image = sitk.GetImageFromArray(zeroArray.astype(float).astype(np.uint8))  \n",
    "    nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    if(nan_count>0):\n",
    "        raise ValueError(f\"!!! nan in image would be saved as {newPathLab}\")\n",
    "\n",
    "    image.SetSpacing(image3D.GetSpacing())\n",
    "    image.SetOrigin(image3D.GetOrigin())\n",
    "    image.SetDirection(image3D.GetDirection())   \n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    writer.SetFileName(newPathLab)\n",
    "    writer.Execute(image)\n",
    "\n",
    "def copy_changing_type(source, dest):\n",
    "    image= sitk.ReadImage(source)\n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in {source}\")\n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    image=sitk.Cast(image, sitk.sitkFloat32)\n",
    "    writer = sitk.ImageFileWriter() \n",
    "    writer.SetFileName(dest)\n",
    "    writer.Execute(image)\n",
    "    return dest\n",
    "\n",
    "# mod=\"adc\"\n",
    "def get_key_by_value(mod,channel_names):\n",
    "    return list(channel_names.keys())[list(channel_names.values()).index(mod)]\n",
    "\n",
    "def prepare_out_paths(group,modalities_of_intrest,labelsTrFolder,imagesTrFolder,non_mri_inputs,channel_names ):\n",
    "    #preparing names\n",
    "    for_id=get_4_id(group[0])\n",
    "    label_new_path= join(labelsTrFolder,f\"9{for_id}00.nii.gz\" )\n",
    "    # prostate_path=join(imagesTrFolder,f\"9{for_id}00_000{3}.nii.gz\" )\n",
    "    out_pathsDict= list(map( lambda mod:(mod,join(imagesTrFolder,f\"9{for_id}00_000{get_key_by_value(mod,channel_names)}.nii.gz\" )) ,np.unique(modalities_of_intrest+non_mri_inputs) ))\n",
    "    out_pathsDict=dict(out_pathsDict)\n",
    "    return label_new_path,out_pathsDict\n",
    "\n",
    "# with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "# #with mp.Pool(processes = 1) as pool:\n",
    "#     @curry  \n",
    "#     def pmap(fun,iterable):\n",
    "#         return pool.map(fun,iterable)\n",
    "    \n",
    "def reg_a_to_b_by_metadata_single_c(fixed_image_path,moving_image_path,interpolator):\n",
    "    # print(f\"fixed_image_path {fixed_image_path} moving_image_path {moving_image_path}\")\n",
    "    # moving_image_path=moving_image_path[0]\n",
    "    fixed_image=sitk.ReadImage(fixed_image_path)\n",
    "    moving_image=sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # fixed_image=sitk.Cast(fixed_image, sitk.sitkUInt8)\n",
    "    # moving_image=sitk.Cast(moving_image, sitk.sitkInt)\n",
    "    \n",
    "    arr=sitk.GetArrayFromImage(moving_image)\n",
    "    resampled=sitk.Resample(moving_image, fixed_image, sitk.Transform(3, sitk.sitkIdentity), interpolator, 0)\n",
    "    return sitk.GetArrayFromImage(resampled)\n",
    "\n",
    "\n",
    "def visualize_range(group,main_modality,modalities_of_intrest,non_mri_inputs):\n",
    "\n",
    "    modalit_path_add= list(map( lambda el:(group[1][el]) ,non_mri_inputs))\n",
    "    # print(f\"ggg group[1] {group[1]}\")\n",
    "    # print(f\"modalit_path_add[0][1] {modalit_path_add[0][1]}\")\n",
    "    if(modalit_path_add[0][1][0]==' '):\n",
    "        print(f\"no prostate! {group[0]}\")\n",
    "        return group[0]\n",
    "\n",
    "    modalities_of_intrest_without_main= list(filter( lambda el: el!=main_modality , modalities_of_intrest))   \n",
    "    # modalities_of_intrest_without_main=non_mri_inputs+modalities_of_intrest_without_main\n",
    "\n",
    "    sources_dict=group[1]\n",
    "    sources_dict[non_mri_inputs[0]]=(modalit_path_add[0][1][0],)\n",
    "\n",
    "\n",
    "    registered_modalities_arrs= list(map(lambda mod: reg_a_to_b_by_metadata_single_c(sources_dict[main_modality][0],sources_dict[mod][0], sitk.sitkBSpline)                                    \n",
    "                                                      ,modalities_of_intrest_without_main ))\n",
    "    registered_prostate= list(map(lambda mod: reg_a_to_b_by_metadata_single_c(sources_dict[main_modality][0],sources_dict[mod][0], sitk.sitkNearestNeighbor)                                    \n",
    "                                                      ,non_mri_inputs ))\n",
    "\n",
    "    ########### manage labels\n",
    "\n",
    "\n",
    "    labels_hbv=group[1][modalities_of_intrest_without_main[0]][1]\n",
    "    labels_adc=group[1][main_modality][1]\n",
    "\n",
    "    print(f\"labels_hbv {labels_hbv}\")\n",
    "\n",
    "    labels_hbv=list(map(lambda pathh_moving: reg_a_to_b_by_metadata_single_c(sources_dict[main_modality][0],pathh_moving, sitk.sitkNearestNeighbor)                                    \n",
    "                                                      ,labels_hbv ))\n",
    "\n",
    "    labels= labels_adc+labels_hbv\n",
    "\n",
    "    reduced_sum = np.array(functools.reduce(get_bool_or, labels))\n",
    "    reduced_common = np.array(functools.reduce(get_bool_and, labels))\n",
    "    reduced_common= ndimage.binary_dilation(arr,iterations=2)\n",
    "\n",
    "    labRes=reduced_sum.astype(int)\n",
    "    labRes=labRes+reduced_common.astype(int)\n",
    "    # label_names=list(map(lambda pathh:  \n",
    "    #                      list(filter( lambda el_out:'/' not in el_out ,\n",
    "    #                         list(filter(lambda el: 'lesion' in el  ,pathh.split('_')))))[0]\n",
    "                         \n",
    "    #                      ,labels ))\n",
    "    # label_names= list(filter( lambda el: '/' not in el ,label_names))\n",
    "    # # we want to get sum of all labels of the same name - so lesion 1 sum lesion 2 sum ...\n",
    "    # # then we encode it in separate file \n",
    "    # zipped_names= list(zip(label_names,labels))\n",
    "\n",
    "    # grouped_by_lesion_num = dict(groupby(lambda tupl :tupl[0],zipped_names)).items()\n",
    "    # grouped_by_lesion_num= list(map(lambda grouped :  (grouped[0],list(map(lambda el: el[1],grouped[1])) ) , grouped_by_lesion_num  ))\n",
    "    # print(f\"\\n grouped_by_lesion_num {grouped_by_lesion_num} \\n\")\n",
    "    # grouped_by_lesion_num_arrs= list(map(lambda grouped :  (grouped[0],np.array(functools.reduce(get_bool_or, grouped[1]))),grouped_by_lesion_num  ))\n",
    "    # label_names_uniq=list(map(lambda el: el[0] ,grouped_by_lesion_num))\n",
    "    # label_nums= list(map(lambda name: \"\".join(list(filter(lambda el:el.isdigit(),name)))  ,label_names_uniq))\n",
    "\n",
    "\n",
    "    # grouped_by_lesion_num_arrs= list(map(lambda arr ,ndimage.binary_dilation(arr,iterations=1),grouped_by_lesion_num_arrs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    adc_arr=sitk.GetArrayFromImage(sitk.ReadImage(group[1][main_modality][0]))\n",
    "    prostate_arr= registered_prostate[0]\n",
    "    hbv_arr= registered_modalities_arrs[0]\n",
    "\n",
    "\n",
    "    prostate_arr_indicies= np.argwhere(prostate_arr)\n",
    "\n",
    "\n",
    "\n",
    "    add_padd_z=50\n",
    "    add_padd_x=14\n",
    "    add_padd_y=14\n",
    "\n",
    "    max_z= np.max(prostate_arr_indicies[:,0])+add_padd_z\n",
    "    min_z= np.min(prostate_arr_indicies[:,0])-add_padd_z\n",
    "    # min_z=0\n",
    "    # max_z=adc_arr.shape[0]\n",
    "    max_x= np.max(prostate_arr_indicies[:,1])+add_padd_x\n",
    "    min_x= np.min(prostate_arr_indicies[:,1])-add_padd_x\n",
    "\n",
    "    max_y= np.max(prostate_arr_indicies[:,2])+add_padd_y\n",
    "    min_y= np.min(prostate_arr_indicies[:,2])-add_padd_y\n",
    "    \n",
    "    min_z=max(min_z,0)\n",
    "    min_y=max(min_y,0)\n",
    "    min_x=max(min_x,0)\n",
    "\n",
    "    max_z=min(max_z,prostate_arr.shape[0]-1)\n",
    "    max_x=min(max_x,prostate_arr.shape[1]-1)\n",
    "    max_y=min(max_y,prostate_arr.shape[2]-1)\n",
    "\n",
    "\n",
    "    print(f\"max_z {max_z} min_z {min_z} max_x {max_x} min_x {min_x} max_y {max_y} min_y {min_y}\")\n",
    "\n",
    "    # min_x=0\n",
    "    # max_x=adc_arr.shape[1]\n",
    "\n",
    "    # min_y=0\n",
    "    # max_y=adc_arr.shape[2]\n",
    "\n",
    "    adc_arr=adc_arr[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "    hbv_arr=hbv_arr[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "    prostate_arr=prostate_arr[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "    labRes=labRes[min_z:max_z,min_x:max_x,min_y:max_y]\n",
    "\n",
    "    big_prost_z=einops.reduce(prostate_arr,'z x y-> z','sum')\n",
    "    slice=np.argmax(big_prost_z)\n",
    "\n",
    "    big_prost_x=einops.reduce(prostate_arr,'z x y-> x','sum')\n",
    "    on_x=np.argmax(big_prost_z)\n",
    "\n",
    "    \n",
    "    prost= prostate_arr[slice,:,:]\n",
    "    image_to_disp_big= adc_arr[0,:,:]\n",
    "    image_to_disp_on_x= adc_arr[-1,:,:]\n",
    "    # mean= np.mean(image_to_disp_big.flatten())\n",
    "    # std= np.std(image_to_disp_big.flatten())\n",
    "    # print(f\"stddd {std}\")\n",
    "    # # image_to_disp_big= np.clip(image_to_disp_big,mean+1000, mean-1000)\n",
    "    # image_to_disp_big= np.clip(image_to_disp_big,-10000.0, 100000.0)\n",
    "\n",
    "    # with_boundaries=mark_boundaries(image_to_disp_big, prost.astype(int) )\n",
    "    # with_boundaries=mark_boundaries(image_to_disp_big, prost.astype(int) )\n",
    "    fig, axs = plt.subplots(ncols=3)\n",
    "\n",
    "    # sns.heatmap(image_to_disp_big,cmap=\"Greys\" ,ax=axs[0])\n",
    "    # sns.heatmap(image_to_disp_on_x,cmap=\"Greys\" ,ax=axs[1])\n",
    "    # plt.imshow(with_boundaries)\n",
    "    sns.heatmap(adc_arr[slice,:,:],cmap=\"Greys\" ,ax=axs[0] )\n",
    "    sns.heatmap(hbv_arr[slice,:,:],cmap=\"Greys\" ,ax=axs[1] )\n",
    "    sns.heatmap(labRes[slice,:,:],cmap=\"Greys\" ,ax=axs[2] )\n",
    "    plt.show()\n",
    "\n",
    "    # registered_modalities= list(map(lambda mod: reg_a_to_b(join(temp_dir,mod),group[0],group[1][main_modality][0],group[1][mod][0],group[1][mod][1],reg_prop\n",
    "    #                                                             ,elacticPath,transformix_path,mod)\n",
    "                        # ,modalities_of_intrest_without_main   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'inferred_pg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'inferred_pg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m non_mri_inputs\u001b[39m=\u001b[39m[new_col_name]\n\u001b[1;32m     12\u001b[0m \u001b[39m# with mp.Pool(processes = mp.cpu_count()) as pool:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# with mp.Pool(processes = 1) as pool:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#     @curry  \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#     def pmap(fun,iterable):\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#         return pool.map(fun,iterable)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m ids\u001b[39m=\u001b[39mtoolz\u001b[39m.\u001b[39;49mpipe(sourceFrame\u001b[39m.\u001b[39;49miterrows()\n\u001b[1;32m     19\u001b[0m                                 ,\u001b[39mfilter\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m row: row[\u001b[39m1\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mseries_desc\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39min\u001b[39;49;00m modalities_of_intrest)\n\u001b[1;32m     20\u001b[0m                                 ,\u001b[39mfilter\u001b[39;49m(filter_ids) \u001b[39m# filter out all of the test cases\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m                                 ,groupByMaster\n\u001b[1;32m     22\u001b[0m                                 ,\u001b[39mmap\u001b[39;49m(partial(iterGroupModalities,modalities_of_intrest\u001b[39m=\u001b[39;49mmodalities_of_intrest,label_cols\u001b[39m=\u001b[39;49mlesion_cols,non_mri_inputs\u001b[39m=\u001b[39;49mnon_mri_inputs))\n\u001b[1;32m     23\u001b[0m                                 ,\u001b[39mfilter\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m group: \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m group[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mkeys() )\n\u001b[1;32m     24\u001b[0m                                 ,\u001b[39mlist\u001b[39;49m\n\u001b[1;32m     25\u001b[0m                                 ,\u001b[39mmap\u001b[39;49m(partial(visualize_range,main_modality\u001b[39m=\u001b[39;49mmain_modality,modalities_of_intrest\u001b[39m=\u001b[39;49mmodalities_of_intrest,non_mri_inputs\u001b[39m=\u001b[39;49mnon_mri_inputs))                            \n\u001b[1;32m     26\u001b[0m                                 ,\u001b[39mlist\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[39mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "Cell \u001b[0;32mIn[15], line 70\u001b[0m, in \u001b[0;36miterGroupModalities\u001b[0;34m(groupTuple, modalities_of_intrest, label_cols, non_mri_inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mgrouping the paths into dictionary relative to modalities they represent and lesions on thise \u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mmodalities\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m masterOlds, listRows\u001b[39m=\u001b[39m groupTuple\n\u001b[0;32m---> 70\u001b[0m pathhs\u001b[39m=\u001b[39mtoolz\u001b[39m.\u001b[39;49mpipe(listRows\n\u001b[1;32m     71\u001b[0m             ,\u001b[39mmap\u001b[39;49m(partial(getPathsFromRow,list_columns\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49munique(label_cols\u001b[39m+\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mseries_MRI_path\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m+\u001b[39;49mnon_mri_inputs)))\n\u001b[1;32m     72\u001b[0m             ,myFlatten\n\u001b[1;32m     73\u001b[0m             \u001b[39m# ,filter(lambda el : len(el)>2)\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m             ,\u001b[39mlist\u001b[39;49m\n\u001b[1;32m     75\u001b[0m             ,partial(map_modalities,modalities\u001b[39m=\u001b[39;49mmodalities_of_intrest,non_mri_inputs\u001b[39m=\u001b[39;49mnon_mri_inputs)\n\u001b[1;32m     76\u001b[0m             ,\u001b[39mdict\u001b[39;49m\n\u001b[1;32m     77\u001b[0m             )   \n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m (masterOlds,pathhs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[39mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m, in \u001b[0;36mgetPathsFromRow.<locals>.<lambda>\u001b[0;34m(colName)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetPathsFromRow\u001b[39m(row,list_columns):\n\u001b[1;32m     18\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m    extracting all paths of intrest from row\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     res\u001b[39m=\u001b[39m  \u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m colName : (colName,row[\u001b[39m1\u001b[39;49m][colName] ),list_columns )\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'inferred_pg'"
     ]
    }
   ],
   "source": [
    "\n",
    "test_ids = pd.read_csv('/workspaces/konwersjaJsonData/explore/test_ids.csv' ).to_numpy().flatten()\n",
    "\n",
    "test_ids= list(map(lambda el: str(el).strip(),test_ids ))\n",
    "filter_ids=lambda row: str(row[1]['masterolds']).strip() not in test_ids\n",
    "modalities_of_intrest=['t2w','adc','hbv']\n",
    "cols=sourceFrame.columns\n",
    "noSegCols=list(filter(lambda el: '_noSeg' in el , cols))+['series_MRI_path']\n",
    "lesion_cols=list(filter(lambda el: 'lesion' in el , noSegCols))\n",
    "main_modality = 'adc'\n",
    "non_mri_inputs=[new_col_name]\n",
    "\n",
    "# with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "# with mp.Pool(processes = 1) as pool:\n",
    "#     @curry  \n",
    "#     def pmap(fun,iterable):\n",
    "#         return pool.map(fun,iterable)\n",
    "\n",
    "ids=toolz.pipe(sourceFrame.iterrows()\n",
    "                                ,filter(lambda row: row[1]['series_desc'] in modalities_of_intrest)\n",
    "                                ,filter(filter_ids) # filter out all of the test cases\n",
    "                                ,groupByMaster\n",
    "                                ,map(partial(iterGroupModalities,modalities_of_intrest=modalities_of_intrest,label_cols=lesion_cols,non_mri_inputs=non_mri_inputs))\n",
    "                                ,filter(lambda group: ' ' not in group[1].keys() )\n",
    "                                ,list\n",
    "                                ,map(partial(visualize_range,main_modality=main_modality,modalities_of_intrest=modalities_of_intrest,non_mri_inputs=non_mri_inputs))                            \n",
    "                                ,list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=sourceFrame['masterolds'].to_numpy()\n",
    "99461 in aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(filter(lambda idd: str(idd) in list(map(str,test_ids)), ids))\n",
    "list(filter(lambda idd: int(idd) in list(map(int,test_ids)) , ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (334535848.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/compilerop.py:86\u001b[0m, in \u001b[0;36mCachingCompiler.ast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mast_parse\u001b[39m(\u001b[39mself\u001b[39m, source, filename\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<unknown>\u001b[39m\u001b[39m'\u001b[39m, symbol\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexec\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse code to an AST with the current compiler flags active.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[39m    Arguments are exactly the same as ast.parse (in the standard library),\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    and are passed to the built-in compile function.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcompile\u001b[39;49m(source, filename, symbol, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflags \u001b[39m|\u001b[39;49m PyCF_ONLY_AST, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (334535848.py, line 1)"
     ]
    }
   ],
   "source": [
    "# https://github.com/MIC-DKFZ/nnUNet.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
