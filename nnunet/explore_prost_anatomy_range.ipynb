{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import sys\n",
    "import os.path\n",
    "from os import path as pathOs\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import shutil\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "from pathlib import Path\n",
    "import fileinput\n",
    "import re\n",
    "import subprocess\n",
    "from toolz.itertoolz import groupby\n",
    "import seaborn as sns\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import SimpleITK as sitk\n",
    "import mdai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import mdai\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from pydicom.fileset import FileSet\n",
    "from os import path as pathOs\n",
    "from pathlib import Path\n",
    "import toolz\n",
    "from toolz.curried import pipe, map, filter, get\n",
    "from toolz import curry\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "import nnunetv2\n",
    "\n",
    "import elastixRegister as elastixRegister\n",
    "from elastixRegister import reg_a_to_b\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from toolz.itertoolz import groupby\n",
    "from toolz import curry\n",
    "# import multiprocess\n",
    "# p = multiprocess.Pool(os.cpu_count())\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from scipy import ndimage\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import mdai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import mdai\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from pydicom.fileset import FileSet\n",
    "from os import path as pathOs\n",
    "from pathlib import Path\n",
    "import toolz\n",
    "from toolz.curried import pipe, map, filter, get\n",
    "from toolz import curry\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "import nnunetv2\n",
    "\n",
    "# from elastixRegister import reg_a_to_b,reg_a_to_b_be_meta_data,reg_a_to_b_by_metadata_single_b\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from toolz.itertoolz import groupby\n",
    "from toolz import curry\n",
    "# import multiprocess\n",
    "# p = multiprocess.Pool(os.cpu_count())\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import SimpleITK as sitk\n",
    "from evalutils import SegmentationAlgorithm\n",
    "from evalutils.validators import (UniqueImagesValidator,\n",
    "                                  UniquePathIndicesValidator)\n",
    "from picai_prep.data_utils import atomic_image_write\n",
    "from picai_prep.preprocessing import (PreprocessingSettings, Sample,\n",
    "                                      resample_to_reference_scan)\n",
    "\n",
    "\n",
    "elacticPath='/home/sliceruser/elastixBase/elastix-5.0.1-linux/bin/elastix'\n",
    "transformix_path='/home/sliceruser/elastixBase/elastix-5.0.1-linux/bin/transformix'\n",
    "reg_prop='/workspaces/konwersjaJsonData/nnunet/registration/parameters.txt'  \n",
    "# dataframe with master ids that we should not include in training\n",
    "test_ids_CSVDir='/workspaces/konwersjaJsonData/test_ids.csv'\n",
    "test_ids=pd.read_csv(test_ids_CSVDir)['ids'].to_numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "def reg_a_to_b_by_metadata_single_b(fixed_image_path,moving_image_path,out_folder, interpolator=sitk.sitkNearestNeighbor):\n",
    "    if(len(moving_image_path)<4):\n",
    "        moving_image_path=moving_image_path[0]\n",
    "    fixed_image=sitk.ReadImage(fixed_image_path)\n",
    "    moving_image=sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # fixed_image=sitk.Cast(fixed_image, sitk.sitkUInt8)\n",
    "    # moving_image=sitk.Cast(moving_image, sitk.sitkInt)\n",
    "    \n",
    "    arr=sitk.GetArrayFromImage(moving_image)\n",
    "    resampled=sitk.Resample(moving_image, fixed_image, sitk.Transform(3, sitk.sitkIdentity), interpolator, 0)\n",
    "    \n",
    "    # print(f\" prim sum {np.sum(sitk.GetArrayFromImage(sitk.ReadImage(moving_image_path)).flatten())} \\n suuum {np.sum(sitk.GetArrayFromImage(resampled).flatten())} \")\n",
    "  \n",
    "    writer = sitk.ImageFileWriter()\n",
    "    new_path= join(out_folder,moving_image_path.split('/')[-1])\n",
    "    writer.SetFileName(new_path)\n",
    "    writer.Execute(resampled)\n",
    "\n",
    "    return new_path\n",
    "\n",
    "def reg_a_to_b_by_metadata_single_f(fixed_image_path,moving_image_path,interpolator):\n",
    "\n",
    "    fixed_image=sitk.ReadImage(fixed_image_path)\n",
    "    moving_image=sitk.ReadImage(moving_image_path)\n",
    "    arr=sitk.GetArrayFromImage(moving_image)\n",
    "    resampled=sitk.Resample(moving_image, fixed_image, sitk.Transform(3, sitk.sitkIdentity), interpolator, 0)\n",
    "    return resampled\n",
    "\n",
    "\n",
    "\n",
    "def reg_a_to_b_by_metadata_single_g(fixed_image_path,moving_image_path,out_folder, interpolator=sitk.sitkNearestNeighbor):\n",
    "    if(len(moving_image_path)<4):\n",
    "        moving_image_path=moving_image_path[0]\n",
    "    fixed_image=sitk.ReadImage(fixed_image_path)\n",
    "    moving_image=sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # fixed_image=sitk.Cast(fixed_image, sitk.sitkUInt8)\n",
    "    # moving_image=sitk.Cast(moving_image, sitk.sitkInt)\n",
    "    \n",
    "    arr=sitk.GetArrayFromImage(moving_image)\n",
    "    resampled=sitk.Resample(moving_image, fixed_image, sitk.Transform(3, sitk.sitkIdentity), interpolator, 0)\n",
    "    \n",
    "    # print(f\" prim sum {np.sum(sitk.GetArrayFromImage(sitk.ReadImage(moving_image_path)).flatten())} \\n suuum {np.sum(sitk.GetArrayFromImage(resampled).flatten())} \")\n",
    "  \n",
    "    writer = sitk.ImageFileWriter()\n",
    "    new_path= moving_image_path\n",
    "    writer.SetFileName(new_path)\n",
    "    writer.Execute(resampled)\n",
    "\n",
    "    return new_path\n",
    "\n",
    "\n",
    "def groupByMaster(rowws):\n",
    "    grouped_by_master= groupby(lambda row : row[1]['masterolds'],rowws)\n",
    "    # grouped_by_master=[(key,list(group)) for key, group in grouped_by_master]\n",
    "    return dict(grouped_by_master).items()\n",
    "\n",
    "\n",
    "\n",
    "def get_bool_arr_from_path(pathh):\n",
    "    \"\"\"\n",
    "    given path reads it and return associated array\n",
    "    then it casts it to boolean data type\n",
    "    \"\"\"\n",
    "    imageA=sitk.ReadImage(pathh)\n",
    "    return sitk.GetArrayFromImage(imageA).astype(bool)\n",
    "\n",
    "\n",
    "def getPathsFromRow(row,list_columns):\n",
    "    \"\"\"\n",
    "    extracting all paths of intrest from row\n",
    "    \"\"\"\n",
    "    res=  map( lambda colName : (colName,row[1][colName] ),list_columns )\n",
    "    return res\n",
    "\n",
    "def getListModality(modalityName,pathhs,non_mri_inputs):\n",
    "    \"\"\"\n",
    "    getting paths related to single modality and extracting main MRI image\n",
    "    non_mri_inputs - some inputs that are designed to be put into input channels \n",
    "    \"\"\"\n",
    "    if(modalityName not in non_mri_inputs):\n",
    "        # we are intrested only in paths that has the prostate segmentation\n",
    "        pathhs=list(map(lambda el: el[1],pathhs))\n",
    "        # pathhs= list(filter(lambda el :\"pg_t2w.nii.gz\" not in el , pathhs))\n",
    "        mod_paths = list(filter(lambda pathh :modalityName in  pathh,pathhs))\n",
    "        mri = list(filter(lambda el: '.mha' in el ,mod_paths))\n",
    "        if(len(mri)==0):\n",
    "            return ' ',[]\n",
    "        mri=mri[0]   \n",
    "        mod_paths= list(filter(lambda pathh: '.mha' not in pathh , mod_paths))\n",
    "        return (modalityName,(mri,np.unique(mod_paths).tolist()))\n",
    "    \n",
    "    elif(modalityName in non_mri_inputs):\n",
    "        # colNames=list(map(lambda el: el[0],pathhs))\n",
    "        pathhss= list(filter(lambda el :modalityName in el[0] , pathhs))   \n",
    "        if(len(pathhss)==0):\n",
    "            return ' ',[]        \n",
    "        res= (modalityName, (modalityName,np.unique(pathhss[0][1]).tolist())  )\n",
    "        return res\n",
    "\n",
    "\n",
    "def myFlatten(liist):\n",
    "    return  itertools.chain(*liist)\n",
    "\n",
    "def map_modalities(pathhs,modalities,non_mri_inputs):\n",
    "    all_modalities=modalities+non_mri_inputs\n",
    "    res= toolz.pipe(all_modalities\n",
    "                ,map(partial(getListModality,pathhs=pathhs,non_mri_inputs=non_mri_inputs))\n",
    "                ,list\n",
    "            )\n",
    "    # print(f\"gggg {res}\")\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def iterGroupModalities(groupTuple,modalities_of_intrest,label_cols,non_mri_inputs ):\n",
    "    \"\"\"\n",
    "    grouping the paths into dictionary relative to modalities they represent and lesions on thise \n",
    "    modalities\n",
    "    \"\"\"\n",
    "    masterOlds, listRows= groupTuple\n",
    "    pathhs=toolz.pipe(listRows\n",
    "                ,map(partial(getPathsFromRow,list_columns=np.unique(label_cols+['series_MRI_path']+non_mri_inputs)))\n",
    "                ,myFlatten\n",
    "                # ,filter(lambda el : len(el)>2)\n",
    "                ,list\n",
    "                ,partial(map_modalities,modalities=modalities_of_intrest,non_mri_inputs=non_mri_inputs)\n",
    "                ,dict\n",
    "                )   \n",
    "    return (masterOlds,pathhs)\n",
    "\n",
    "\n",
    "\n",
    "def get_bool_or(pathA,pathB):\n",
    "    if(isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathA),get_bool_arr_from_path(pathB))\n",
    "    elif(isinstance(pathA, str) and not isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathA),pathB)\n",
    "    elif(not isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_or(get_bool_arr_from_path(pathB),pathA)\n",
    "    else:\n",
    "        return np.logical_or(pathB,pathA)\n",
    "\n",
    "\n",
    "def get_bool_and(pathA,pathB):\n",
    "    if(isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathA),get_bool_arr_from_path(pathB))\n",
    "    elif(isinstance(pathA, str) and not isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathA),pathB)\n",
    "    elif(not isinstance(pathA, str) and isinstance(pathB, str)):\n",
    "        return np.logical_and(get_bool_arr_from_path(pathB),pathA)\n",
    "    else:\n",
    "        return np.logical_and(pathB,pathA)\n",
    "\n",
    "def get_4_id(masterolds):\n",
    "    \"\"\"\n",
    "    take master id and changes it into string that starts with 0s and have always length 4\n",
    "    \"\"\"\n",
    "    masteroldsStand=str(masterolds)\n",
    "    if(len(masteroldsStand)==1):\n",
    "        return f\"000{masteroldsStand}\"\n",
    "    elif(len(masteroldsStand)==2):\n",
    "        return f\"00{masteroldsStand}\"\n",
    "    elif(len(masteroldsStand)==3):\n",
    "        return f\"0{masteroldsStand}\"\n",
    "    return masteroldsStand\n",
    "\n",
    "\n",
    "def get_id_from_file_name(path_str):\n",
    "    path_str=path_str.replace('.nii.gz','')\n",
    "    path_str=path_str[1:5]\n",
    "    return int(path_str)\n",
    "\n",
    "def add_t2w_to_name(source):\n",
    "    if(source==' '):\n",
    "        return ' '\n",
    "    if('t2w' in source):\n",
    "        return source\n",
    "    new_path= source.replace('.nii.gz','_t2w.nii.gz')\n",
    "    copy_changing_type(source, new_path)\n",
    "    return new_path\n",
    "\n",
    "def add_inferred_full_prost_to_dataframe(dir_inferred_prost, df,new_col_name):\n",
    "    \"\"\" \n",
    "    we have some inferred anatomical segmentations done by previous \n",
    "    models now we want to take the folder with \n",
    "    \"\"\"\n",
    "    list_files= os.listdir(dir_inferred_prost)\n",
    "    list_files= list(filter(lambda el : el[0]=='9' ,list_files ))\n",
    "    list_ids= list(map(get_id_from_file_name,list_files))\n",
    "    list_files= list(map( lambda el: f\"{dir_inferred_prost}/{el}\" ,list_files))\n",
    "    file_and_id= dict(list(zip(list_ids,list_files)))\n",
    "    new_col_dat= list(map( lambda el: file_and_id.get(el,' ') ,df['masterolds'].to_numpy() ))\n",
    "    #changing path name to mark it is t2w related\n",
    "    new_col_dat= list(map(add_t2w_to_name,new_col_dat))\n",
    "\n",
    "    df[new_col_name]=new_col_dat\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_from_arr(zeroArray,image3D):\n",
    "    \"\"\"\n",
    "    given array saves it to file into defined path using simpleitk\n",
    "    \"\"\"\n",
    "    image = sitk.GetImageFromArray(zeroArray.astype(float).astype(np.uint8))  \n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in image would be saved as {newPathLab}\")\n",
    "\n",
    "    image.SetSpacing(image3D.GetSpacing())\n",
    "    image.SetOrigin(image3D.GetOrigin())\n",
    "    image.SetDirection(image3D.GetDirection())   \n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    return image\n",
    "\n",
    "\n",
    "def save_from_arr(zeroArray,image3D,newPathLab):\n",
    "    \"\"\"\n",
    "    given array saves it to file into defined path using simpleitk\n",
    "    \"\"\"\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    image = get_from_arr(zeroArray,image3D)\n",
    "    # image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    writer.SetFileName(newPathLab)\n",
    "    writer.Execute(image)\n",
    "    return newPathLab\n",
    "\n",
    "def copy_changing_type(source, dest):\n",
    "    image= sitk.ReadImage(source)\n",
    "    # nan_count=np.sum(np.isnan(np.array(sitk.GetArrayFromImage(image)).flatten()))\n",
    "    # if(nan_count>0):\n",
    "    #     raise ValueError(f\"!!! nan in {source}\")\n",
    "    image = sitk.DICOMOrient(image, 'LPS')\n",
    "    image.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)) \n",
    "    image=sitk.Cast(image, sitk.sitkFloat32)\n",
    "    writer = sitk.ImageFileWriter() \n",
    "    writer.SetFileName(dest)\n",
    "    writer.Execute(image)\n",
    "    return dest\n",
    "\n",
    "# mod=\"adc\"\n",
    "def get_key_by_value(mod,channel_names):\n",
    "    return list(channel_names.keys())[list(channel_names.values()).index(mod)]\n",
    "\n",
    "def prepare_out_paths(group,modalities_of_intrest,labelsTrFolder,imagesTrFolder,non_mri_inputs,channel_names ):\n",
    "    #preparing names\n",
    "    for_id=get_4_id(group[0])\n",
    "    label_new_path= join(labelsTrFolder,f\"9{for_id}00.nii.gz\" )\n",
    "    # prostate_path=join(imagesTrFolder,f\"9{for_id}00_000{3}.nii.gz\" )\n",
    "    out_pathsDict= list(map( lambda mod:(mod,join(imagesTrFolder,f\"9{for_id}00_000{get_key_by_value(mod,channel_names)}.nii.gz\" )) ,np.unique(modalities_of_intrest+non_mri_inputs) ))\n",
    "    out_pathsDict=dict(out_pathsDict)\n",
    "    return label_new_path,out_pathsDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def set_common_prhysical_data():\n",
    "\n",
    "#     image_out.SetOrigin(img.GetOrigin())\n",
    "#     image_out.SetSpacing(img.GetSpacing())\n",
    "#     #set to RAI\n",
    "#     image_out.SetDirection(tuple(1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0))\n",
    "\n",
    "def write_file(image,outputImageFileName):\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.SetFileName(outputImageFileName)\n",
    "    writer.Execute(image)\n",
    "\n",
    "def add_files(group,main_modality,modalities_of_intrest,reg_prop,elacticPath,transformix_path,labelsTrFolder\n",
    "              ,imagesTrFolder,process_labels,non_mri_inputs,channel_names,is_to_preprocess ):\n",
    "    \"\"\"\n",
    "    first register images and their respective labels to t2w\n",
    "    then reduces all labels into their sum\n",
    "    then saves mri and reduced labels into nnunet workdir to get structure the same as in baseline picai nnunet algorithm\n",
    "    \"\"\"\n",
    "    modalit_path_add= list(map( lambda el:(group[1][el]) ,non_mri_inputs))\n",
    "    filtered= list(filter(lambda el: el==' ',modalit_path_add))\n",
    "\n",
    "    if len(filtered)!=0:\n",
    "        return (' ',{})\n",
    "    \n",
    "    \n",
    "    label_new_path,out_pathsDict=prepare_out_paths(group,modalities_of_intrest,labelsTrFolder,imagesTrFolder,non_mri_inputs,channel_names )\n",
    "    label_new_path_prim=label_new_path\n",
    "    temp_dir = tempfile.mkdtemp() # temporary directory\n",
    "    modalities_of_intrest_without_main= list(filter( lambda el: el!=main_modality , modalities_of_intrest))\n",
    "    modalities=[]\n",
    "    labels=[]\n",
    "    mris=[]\n",
    "    newPaths=[]\n",
    "\n",
    "\n",
    "\n",
    "    modalities.append(main_modality)\n",
    "    # zipped_modalit_path = list(zip(modalities,mris))\n",
    "    \n",
    "\n",
    "    mris=list(map(lambda mod:   reg_a_to_b_by_metadata_single_b(group[1][main_modality][0],group[1][mod][0],temp_dir, sitk.sitkBSpline)\n",
    "                 ,modalities_of_intrest_without_main))\n",
    "\n",
    "\n",
    "    mris=list(mris)\n",
    "    # mris.append(group[1][main_modality][0])    \n",
    "    mris.append(group[1][main_modality][0])    \n",
    "    modalities_of_intrest_without_main.append(main_modality)\n",
    "    modalities=modalities_of_intrest_without_main\n",
    "\n",
    "    #adding to the list the labels from main modality thay did not needed to be registered\n",
    "    labels=np.array(labels+group[1][main_modality][1]).flatten()\n",
    "    # print(f\"labels {labels}  group[1][main_modality] {group[1][main_modality]} \")\n",
    "    example_scan=[]\n",
    "    \n",
    "    if(len(labels)>0):\n",
    "        zipped_modalit_path = list(zip(modalities,mris))\n",
    "        # print(f\"zipped_modalit_path {zipped_modalit_path}\")\n",
    "        #zipping for starmap use        \n",
    "        zipped_modalit_path= list(map( lambda tupl:(tupl[1], out_pathsDict[tupl[0]]) ,zipped_modalit_path))\n",
    "        # print(f\"mmmm mris {mris} modalities_of_intrest {modalities_of_intrest}\")\n",
    "        mris_for_sample=[mris[2],mris[0],mris[1]]\n",
    "        sample = Sample(\n",
    "        scans=[\n",
    "            sitk.ReadImage(str(path))\n",
    "            for path in mris_for_sample\n",
    "        ],\n",
    "        settings=PreprocessingSettings(\n",
    "            # physical_size=[128.0, 96.0, 118.0],\n",
    "            physical_size=[138.0, 128.0, 124.0],\n",
    "            crop_only=True\n",
    "        )\n",
    "        )\n",
    "\n",
    "        # perform preprocessing\n",
    "        sample.preprocess()\n",
    "        # print(f\"ssss sample.scans {sample.scans}\")\n",
    "        out=[zipped_modalit_path[2][1],zipped_modalit_path[0][1],zipped_modalit_path[1][1]]\n",
    "        # list(itertools.starmap(write_file,list(zip(sample.scans, out ))))\n",
    "\n",
    "        t2w_arr= sitk.GetArrayFromImage(sample.scans[0])\n",
    "        adc_arr= sitk.GetArrayFromImage(sample.scans[1])\n",
    "        hbv_arr= sitk.GetArrayFromImage(sample.scans[2])\n",
    "\n",
    "\n",
    "        slicee=t2w_arr.shape[0]//2\n",
    "        label_new_paths,newPaths= process_labels(labels,group,main_modality,label_new_path,newPaths,out_pathsDict)\n",
    "\n",
    "        label_prim=sitk.GetArrayFromImage(sitk.ReadImage(label_new_paths[0]))\n",
    "\n",
    "        label=sitk.Resample(sitk.ReadImage(label_new_paths[0]), sample.scans[0], sitk.Transform(3, sitk.sitkIdentity), sitk.sitkNearestNeighbor, 0)\n",
    "\n",
    "        label=sitk.GetArrayFromImage(label)\n",
    "        label=(label>0)\n",
    "        # sns.heatmap(image_to_disp_big,cmap=\"Greys\" ,ax=axs[0])\n",
    "        # sns.heatmap(image_to_disp_on_x,cmap=\"Greys\" ,ax=axs[1])\n",
    "        # plt.imshow(with_boundaries)\n",
    "\n",
    "        # sns.heatmap(adc_arr[slicee,:,:],cmap=\"Greys\" ,ax=axs[2] )\n",
    "        # sns.heatmap(hbv_arr[slicee,:,:],cmap=\"Greys\" ,ax=axs[1] )\n",
    "        # sns.heatmap(t2w_arr[slicee,:,:],cmap=\"Greys\" ,ax=axs[0] )\n",
    "\n",
    "        # plt.imshow(mark_boundaries(t2w_arr[t2w_arr.shape[0]//2,:,:],label.astype(int)) ,ax=axs[0])\n",
    "        # plt.imshow(mark_boundaries(t2w_arr[:,t2w_arr.shape[1]//2,:],label.astype(int)),ax=axs[1] )\n",
    "        # plt.imshow(mark_boundaries(t2w_arr[:,:,t2w_arr.shape[2]//2],label.astype(int)),ax=axs[2] )\n",
    "\n",
    "        if(np.sum((label_prim>0).flatten())>np.sum(label.flatten())):\n",
    "            fig, axs = plt.subplots(ncols=3,figsize=(30, 10))\n",
    "\n",
    "            rows = 1\n",
    "            columns = 3\n",
    "\n",
    "\n",
    "            on_z=einops.reduce(label,'z x y-> z','sum')\n",
    "            on_z=np.argmax(on_z)\n",
    "\n",
    "            on_x=einops.reduce(label,'z x y-> x','sum')\n",
    "            on_x=np.argmax(on_x)\n",
    "\n",
    "            on_y=einops.reduce(label,'z x y-> y','sum')\n",
    "            on_y=np.argmax(on_y)\n",
    "\n",
    "\n",
    "            # Adds a subplot at the 1st position\n",
    "            fig.add_subplot(rows, columns, 1)\n",
    "            t2w_arr=t2w_arr*100\n",
    "            # showing image\n",
    "            plt.imshow(mark_boundaries(t2w_arr[on_z,:,:],label[on_z,:,:].astype(int)))\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Adds a subplot at the 2nd position\n",
    "            fig.add_subplot(rows, columns, 2)\n",
    "            \n",
    "            # showing image\n",
    "            plt.imshow(mark_boundaries(t2w_arr[:,on_x,:],label[:,on_x,:].astype(int)))\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Adds a subplot at the 3rd position\n",
    "            fig.add_subplot(rows, columns, 3)\n",
    "            \n",
    "            # showing image\n",
    "            plt.imshow(mark_boundaries(t2w_arr[:,:,on_y],label[:,:,on_y].astype(int)))\n",
    "            plt.axis('off')\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # sns.heatmap(t2w_arr[t2w_arr.shape[0]//2,:,:],cmap=\"Greys\" ,ax=axs[0])\n",
    "            # sns.heatmap(t2w_arr[:,t2w_arr.shape[1]//2,:],cmap=\"Greys\",ax=axs[1] )\n",
    "            # sns.heatmap(t2w_arr[:,:,t2w_arr.shape[2]//2],cmap=\"Greys\",ax=axs[2] )\n",
    "            plt.show()\n",
    "            # example_scan=zipped_modalit_path[2][1]\n",
    "\n",
    "\n",
    "\n",
    "            return \" \" #(group[0],dict(newPaths))\n",
    "    return \" \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_prepare_nnunet(dataset_id, modalities_of_intrest,channel_names,label_names,label_cols,process_labels,non_mri_inputs\n",
    "                        ,sourceFrame,main_modality,for_filter_unwanted=None,is_test_prep=False,is_to_preprocess=True,generate_plans=True):\n",
    "    \"\"\"\n",
    "    main function for preparing nnunet\n",
    "    \"\"\"\n",
    "    #first removing old data\n",
    "    nNunetBaseFolder='/home/sliceruser/nnunetMainFolder'\n",
    "\n",
    "    shutil.rmtree(f\"{nNunetBaseFolder}/nnUNet_preprocessed\")\n",
    "    shutil.rmtree(f\"{nNunetBaseFolder}/nnUNet_raw\")\n",
    "\n",
    "\n",
    "    taskName= f\"Dataset{dataset_id}_Prostate\"\n",
    "    taskFolder = join(nNunetBaseFolder,'nnUNet_raw',taskName)\n",
    "    preprocesss_folder= join(nNunetBaseFolder,'nnUNet_preprocessed')\n",
    "    results_folder= join(nNunetBaseFolder,'nnUNet_results')\n",
    "    mainResults_folder=\"/home/sliceruser/nnUNet_results\"\n",
    "    imagesTrFolder= join(taskFolder,'imagesTr')\n",
    "    labelsTrFolder= join(taskFolder,'labelsTr')\n",
    "    imagesTsFolder= join(taskFolder,'imagesTs')\n",
    "    json_path= join(taskFolder,'dataset.json')\n",
    "\n",
    "    # main modality that will be set as a reference and others will be registered to it \n",
    "\n",
    "\n",
    "    os.makedirs(nNunetBaseFolder ,exist_ok = True)\n",
    "    # os.makedirs(join(nNunetBaseFolder,'nnUNet_raw_data_base') ,exist_ok = True)\n",
    "    # os.makedirs(join(nNunetBaseFolder,'nnUNet_raw_data_base','nnUNet_raw_data') ,exist_ok = True)\n",
    "    os.makedirs(taskFolder ,exist_ok = True)\n",
    "    os.makedirs(imagesTrFolder ,exist_ok = True)\n",
    "    os.makedirs(labelsTrFolder ,exist_ok = True)\n",
    "    os.makedirs(preprocesss_folder ,exist_ok = True)\n",
    "    os.makedirs(results_folder ,exist_ok = True)\n",
    "    os.makedirs(mainResults_folder ,exist_ok = True)\n",
    "    os.makedirs(join(mainResults_folder,taskName),exist_ok = True)\n",
    "    \n",
    "\n",
    "    if(for_filter_unwanted==None):\n",
    "        for_filter_unwanted=lambda group: True\n",
    "    grouped_rows=[]\n",
    "    \n",
    "    filter_out_test_ids=lambda row: row[1]['masterolds'] not in test_ids\n",
    "    filter_in_test_ids=lambda row: row[1]['masterolds'] in test_ids\n",
    "    filter_ids=filter_out_test_ids\n",
    "\n",
    "\n",
    "    label_paths= toolz.pipe(sourceFrame.iterrows()\n",
    "                            ,filter(lambda row: row[1]['series_desc'] in modalities_of_intrest)\n",
    "                            ,filter(filter_ids) # filter out all of the test cases\n",
    "                            ,groupByMaster\n",
    "                            ,map(partial(iterGroupModalities,modalities_of_intrest=modalities_of_intrest,label_cols=label_cols,non_mri_inputs=non_mri_inputs))\n",
    "                            ,list\n",
    "                            ,filter(lambda group: ' ' not in group[1].keys() )\n",
    "                            ,filter(for_filter_unwanted )\n",
    "                            ,list\n",
    "                            ,map(partial(add_files,main_modality=main_modality,modalities_of_intrest=modalities_of_intrest,reg_prop=reg_prop,\n",
    "                                            elacticPath=elacticPath,transformix_path=transformix_path,labelsTrFolder=labelsTrFolder,imagesTrFolder=imagesTrFolder\n",
    "                                            ,process_labels=process_labels,non_mri_inputs=non_mri_inputs,channel_names=channel_names,is_to_preprocess=is_to_preprocess ))\n",
    "                            ,list\n",
    "                            ,filter(lambda el: el!=' ')                                \n",
    "                            ,list\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return grouped_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "segmenation where target is the sum of t2w,adc,hbv labels and we add as input additionally whole prostate segmentations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import mdai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import mdai\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from pydicom.fileset import FileSet\n",
    "from os import path as pathOs\n",
    "from pathlib import Path\n",
    "import toolz\n",
    "from toolz.curried import pipe, map, filter, get\n",
    "from toolz import curry\n",
    "from os.path import basename, dirname, exists, isdir, join, split\n",
    "import nnunetv2\n",
    "\n",
    "\n",
    "from toolz.itertoolz import groupby\n",
    "from toolz import curry\n",
    "# import multiprocess\n",
    "# p = multiprocess.Pool(os.cpu_count())\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import os\n",
    "from subprocess import Popen\n",
    "import subprocess\n",
    "\n",
    "\n",
    "#metadata directory\n",
    "resCSVDir='/home/sliceruser/workspaces/konwersjaJsonData/outCsv/resCSV.csv'\n",
    "#directory with inferred prostates\n",
    "\n",
    "# dir_inferred_prost='/home/sliceruser/workspaces/konwersjaJsonData/my_prost_infered'\n",
    "\n",
    "# dir_inferred_prost='/workspaces/prost_anatomy_seg/data/my_prost_infered'\n",
    "sourceFrame = pd.read_csv(resCSVDir) \n",
    "# new_col_name= 'inferred_pg'\n",
    "\n",
    "\n",
    "\n",
    "def get_id_from_file_name(path_str):\n",
    "    path_str=path_str.replace('.nii.gz','')\n",
    "    path_str=path_str[1:5]\n",
    "    return int(path_str)\n",
    "\n",
    "# def add_t2w_to_name(source):\n",
    "#     if(source==' '):\n",
    "#         return ' '\n",
    "#     # if('t2w' in source):\n",
    "#     #     return source\n",
    "#     # new_path= source.replace('.nii.gz','_t2w.nii.gz')\n",
    "#     # copy_changing_type(source, new_path)\n",
    "#     # return new_path\n",
    "#     return source\n",
    "    \n",
    "\n",
    "# def add_inferred_full_prost_to_dataframe(dir_inferred_prost, df,new_col_name):\n",
    "#     \"\"\" \n",
    "#     we have some inferred anatomical segmentations done by previous \n",
    "#     models now we want to take the folder with \n",
    "#     \"\"\"\n",
    "#     list_files= os.listdir(dir_inferred_prost)\n",
    "#     list_files= list(filter(lambda el : el[0]=='9' ,list_files ))\n",
    "#     list_ids= list(map(get_id_from_file_name,list_files))\n",
    "#     list_files= list(map( lambda el: f\"{dir_inferred_prost}/{el}\" ,list_files))\n",
    "#     file_and_id= dict(list(zip(list_ids,list_files)))\n",
    "#     new_col_dat= list(map( lambda el: file_and_id.get(el,' ') ,df['masterolds'].to_numpy() ))\n",
    "#     #changing path name to mark it is t2w related\n",
    "#     new_col_dat= list(map(add_t2w_to_name,new_col_dat))\n",
    "\n",
    "#     df[new_col_name]=new_col_dat\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "cols=sourceFrame.columns\n",
    "noSegCols=list(filter(lambda el: '_noSeg' in el , cols))+['series_MRI_path']\n",
    "lesion_cols=list(filter(lambda el: 'lesion' in el , noSegCols))\n",
    "main_modality = 't2w'\n",
    "\n",
    "# sourceFrame=add_inferred_full_prost_to_dataframe(dir_inferred_prost, sourceFrame,new_col_name)\n",
    "# modalities that we want to include in the model\n",
    "main_modality = 't2w'\n",
    "modalities_of_intrest=['t2w','adc','hbv']\n",
    "\n",
    "# prostate_col= 'pg_noSeg'\n",
    "# new_col_name=prostate_col\n",
    "\n",
    "# new_col_name= 'inferred_pg'\n",
    "\n",
    "non_mri_inputs=[]\n",
    "# prostate_col= new_col_name # name of the column with segmentaton of whole prostate gland\n",
    "\n",
    "anatomic_cols=['afs_noSeg','cz_noSeg','pz_noSeg','tz_noSeg','sv_l_noSeg','sv_r_noSeg','ur_noSeg','pg_noSeg']\n",
    "# anatomic_cols=['afs_noSeg']\n",
    "\n",
    "label_cols=anatomic_cols\n",
    "# label_cols=anatomic_cols+[prostate_col]\n",
    "channel_names={  \n",
    "    \"0\": \"t2w\", \n",
    "    \"1\": \"adc\", \n",
    "    \"2\": \"hbv\", \n",
    "    }\n",
    "\n",
    "\n",
    "label_names= {  \n",
    "    \"background\": 0,\n",
    "    \"pz\": 1,\n",
    "    \"tz\": 2,\n",
    "    \"sv\" :3,\n",
    "    \"full_prost\":[1,2]\n",
    "    }\n",
    "\n",
    "# sv_l_noSeg 'ur' \n",
    "# label_names= {  # THIS IS DIFFERENT NOW!\n",
    "#     \"background\": 0,\n",
    "#     \"afs\": 1,\n",
    "#     }\n",
    "\n",
    "def get_int_arr_from_path(pathh):\n",
    "    \"\"\"\n",
    "    given path reads it and return associated array\n",
    "    then it casts it to boolean data type\n",
    "    \"\"\"\n",
    "    index=15\n",
    "    to_ignore=False\n",
    "    if('afs' in pathh):\n",
    "        index=2\n",
    "    elif('cz' in pathh):\n",
    "        index=1        \n",
    "    elif('pz' in pathh):\n",
    "        index=1\n",
    "    elif('tz' in pathh):\n",
    "        index=2\n",
    "    elif('sv_l' in pathh):\n",
    "        index=3    \n",
    "    elif('sv_r' in pathh):\n",
    "        index=3          \n",
    "    # elif('pg_t2w' in pathh):\n",
    "    #     print(f\"pg path {pathh}\")\n",
    "\n",
    "    #     index=9                 \n",
    "    elif('ur' in pathh):\n",
    "        index=8          \n",
    "    else:\n",
    "        to_ignore=True\n",
    "    imageA=sitk.ReadImage(pathh)\n",
    "    imageA=sitk.GetArrayFromImage(imageA)\n",
    "    if(to_ignore):\n",
    "        return np.zeros_like(imageA)\n",
    "    return np.array(imageA.astype(bool).astype(np.uint8) *(index))\n",
    "\n",
    "def get_int_arr_from_path_full_prostate(pathh):\n",
    "\n",
    "    index=15\n",
    "    to_ignore=False      \n",
    "    if('pg_t2w' in pathh):\n",
    "        index=9                 \n",
    "    # elif('ur' in pathh):\n",
    "    #     index=8          \n",
    "    else:\n",
    "        to_ignore=True\n",
    "    imageA=sitk.ReadImage(pathh)\n",
    "    imageA=sitk.GetArrayFromImage(imageA)\n",
    "    if(to_ignore):\n",
    "        return np.zeros_like(imageA)\n",
    "    return np.array(imageA.astype(bool).astype(np.uint8) *(index))\n",
    "\n",
    "\n",
    "def process_labels_prim(labels,group,main_modality,label_new_path,zipped_modalit_path,out_pathsDict):\n",
    "    # we get the sum of all labels \n",
    "    arrays= list(map(get_int_arr_from_path,labels))\n",
    "    # arrays= list(map(list,arrays))\n",
    "    reduced = np.sum(np.stack(arrays,axis=0),axis=0).astype(np.uint8)\n",
    "    arrays_b= list(map(get_int_arr_from_path_full_prostate,labels))\n",
    "    reduced_b= np.sum(np.stack(arrays_b,axis=0),axis=0).astype(np.uint8)\n",
    "    #in spots where urethra is set in prostate we set it as tz\n",
    "    mask=np.logical_and((reduced_b==9),(reduced==8))\n",
    "    reduced[mask]=2\n",
    "    #we romeve rest of urethra\n",
    "    mask= (reduced==8)\n",
    "    reduced[mask]=0\n",
    "\n",
    "    print(np.unique(reduced))\n",
    "    save_from_arr(reduced,sitk.ReadImage(group[1][main_modality][0]),label_new_path)\n",
    "    return [label_new_path],zipped_modalit_path\n",
    "\n",
    "\n",
    "def for_filter_unwanted(group):\n",
    "    \"\"\" \n",
    "    we want only cases where  afs cz pz and tz are indicated\n",
    "    \"\"\"\n",
    "\n",
    "    # print(f\"tttt {group[1]['t2w'][1]}\")\n",
    "    # print(f\"lll {len(group[1]['t2w'][1])}\")\n",
    "\n",
    "    # return len(group[1]['t2w'][1])==5\n",
    "    return True\n",
    "\n",
    "\n",
    "grouped_rows= main_prepare_nnunet('294',modalities_of_intrest,channel_names,label_names,label_cols,process_labels_prim,non_mri_inputs,sourceFrame,main_modality,for_filter_unwanted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
